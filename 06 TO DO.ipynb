{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99e4b5e-45b0-412d-a590-fc3e5c378a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temps_clean shape: (365, 2)\n",
      "dias shape: (365,)\n",
      "outliers detectados: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def monthday_to_days(month, day):\n",
    "    month = np.asarray(month, dtype=int)\n",
    "    day = np.asarray(day, dtype=int)\n",
    "    month_days = np.array([31,28,31,30,31,30,31,31,30,31,30,31], dtype=int)  # 2017\n",
    "    month_starts = np.concatenate(([0], np.cumsum(month_days)[:-1]))\n",
    "    return month_starts[month - 1] + (day - 1)   # enero 1 -> 0\n",
    "\n",
    "def moving_average(x, window=30):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    w = np.ones(window, dtype=float) / window\n",
    "    return np.convolve(x, w, mode=\"same\")\n",
    "\n",
    "def iqr_outlier_mask(x, k=1.5):\n",
    "    q1, q3 = np.percentile(x, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - k * iqr\n",
    "    high = q3 + k * iqr\n",
    "    return (x < low) | (x > high)\n",
    "\n",
    "def load_and_preprocess(path=\"kumpula-weather-2017.csv\"):\n",
    "    data = np.genfromtxt(path, delimiter=\",\", names=True, dtype=None, encoding=\"utf-8\")\n",
    "\n",
    "    month = data[\"m\"].astype(int)\n",
    "    day = data[\"d\"].astype(int)\n",
    "    temp = data[\"Air_temperature_degC\"].astype(float)\n",
    "\n",
    "    dias = monthday_to_days(month, day).astype(float)\n",
    "\n",
    "    # limpiar NaN/inf\n",
    "    valid = np.isfinite(dias) & np.isfinite(temp)\n",
    "    dias = dias[valid]\n",
    "    temp = temp[valid]\n",
    "\n",
    "    # ordenar por d√≠a\n",
    "    idx = np.argsort(dias)\n",
    "    dias = dias[idx]\n",
    "    temp = temp[idx]\n",
    "\n",
    "    # anomal√≠as\n",
    "    ma30 = moving_average(temp, window=30)\n",
    "    anomalies = temp - ma30\n",
    "\n",
    "    # outliers \n",
    "    outliers = iqr_outlier_mask(anomalies, k=1.5)\n",
    "\n",
    "    temps_clean = np.column_stack([temp, anomalies])  # (N,2)\n",
    "    return temps_clean, dias, outliers\n",
    "\n",
    "temps_clean, dias, outlier_mask = load_and_preprocess(\"kumpula-weather-2017.csv\")\n",
    "\n",
    "print(\"temps_clean shape:\", temps_clean.shape)  # (N,2)\n",
    "print(\"dias shape:\", dias.shape)                # (N,)\n",
    "print(\"outliers detectados:\", int(outlier_mask.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a548a8a5-d11c-4bbd-8164-f3e30a3d0549",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ffe6f0; padding:15px; border-radius:10px; border:1px solid #ffb3d9\">\n",
    "\n",
    "üå∏ **Ejercicio 1 - Procesamiento de datos**\n",
    "\n",
    "Se cargaron los datos de temperatura y se transformaron las fechas (mes y d√≠a) a d√≠as del a√±o para facilitar el an√°lisis temporal.\n",
    "\n",
    "Luego, se limpiaron los datos eliminando valores inv√°lidos y se ordenaron cronol√≥gicamente. Se calcul√≥ un promedio m√≥vil de 30 d√≠as para obtener la tendencia de la temperatura y, a partir de este, se determinaron las anomal√≠as.\n",
    "\n",
    "Finalmente, se identificaron outliers mediante el m√©todo del rango intercuart√≠lico (IQR), permitiendo detectar variaciones an√≥malas en la serie.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48de5eb-7897-4ba1-b90c-36f4e23fa36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dias shape: (365,)\n",
      "temps_clean shape: (365, 2)\n",
      "smooth7 shape: (365,)\n",
      "trend shape: (365,)\n",
      "seasonal shape: (365,)\n",
      "residual shape: (365,)\n",
      "forecast shapes: (30,) (30,)\n",
      "Todo OK ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import wraps\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"kumpula-weather-2017.csv\")\n",
    "\n",
    "month = pd.to_numeric(df[\"m\"], errors=\"coerce\").to_numpy()\n",
    "day   = pd.to_numeric(df[\"d\"], errors=\"coerce\").to_numpy()\n",
    "temp  = pd.to_numeric(df[\"Air temperature (degC)\"], errors=\"coerce\").to_numpy()\n",
    "\n",
    "# month-day \n",
    "month_days = np.array([31,28,31,30,31,30,31,31,30,31,30,31], dtype=int)\n",
    "month_starts = np.concatenate(([0], np.cumsum(month_days)[:-1]))\n",
    "dias = month_starts[month.astype(int) - 1] + (day.astype(int) - 1)\n",
    "\n",
    "# limpiar NaN/inf\n",
    "valid = np.isfinite(dias) & np.isfinite(temp)\n",
    "dias = dias[valid].astype(float)\n",
    "temp = temp[valid].astype(float)\n",
    "\n",
    "# anomal√≠a = temp - media m√≥vil 30 d√≠as\n",
    "mov30 = np.convolve(temp, np.ones(30)/30, mode=\"same\")\n",
    "anom = temp - mov30\n",
    "\n",
    "temps_clean = np.column_stack([temp, anom])\n",
    "\n",
    "print(\"dias shape:\", dias.shape)\n",
    "print(\"temps_clean shape:\", temps_clean.shape)\n",
    "\n",
    "\n",
    "# clases + herencia + decorator\n",
    "\n",
    "\n",
    "def vectorize(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(self, x, *args, **kwargs):\n",
    "        x = np.asarray(x)\n",
    "        vf = np.vectorize(lambda z: func(self, z, *args, **kwargs))\n",
    "        return vf(x)\n",
    "    return wrapper\n",
    "\n",
    "class TimeSeriesAnalyzer:\n",
    "    def __init__(self, t, y):\n",
    "        self.t = np.asarray(t, dtype=float)\n",
    "        self.y = np.asarray(y, dtype=float)\n",
    "\n",
    "    def smooth(self, window=7):\n",
    "        w = np.ones(window, dtype=float) / window\n",
    "        return np.convolve(self.y, w, mode=\"same\")\n",
    "\n",
    "    @vectorize\n",
    "    def identity(self, x):\n",
    "        return x\n",
    "\n",
    "class WeatherAnalyzer(TimeSeriesAnalyzer):\n",
    "    def seasonal_decompose(self):\n",
    "        # trend: polyfit deg=2\n",
    "        c2 = np.polyfit(self.t, self.y, deg=2)\n",
    "        trend = np.polyval(c2, self.t)\n",
    "\n",
    "    \n",
    "        y_detr = self.y - trend\n",
    "        n = len(y_detr)\n",
    "        fhat = np.fft.rfft(y_detr)\n",
    "        amp = np.abs(fhat)\n",
    "        if len(amp) > 0:\n",
    "            amp[0] = 0.0\n",
    "\n",
    "        k = min(4, len(fhat))\n",
    "        idx = np.argsort(amp)[-k:]\n",
    "\n",
    "        keep = np.zeros_like(fhat, dtype=complex)\n",
    "        keep[idx] = fhat[idx]\n",
    "        seasonal = np.fft.irfft(keep, n=n)\n",
    "\n",
    "        residual = self.y - trend - seasonal\n",
    "        return trend, seasonal, residual\n",
    "\n",
    "    def forecast(self, days_ahead=30):\n",
    "        \n",
    "        m = min(30, len(self.t))\n",
    "        t_last = self.t[-m:]\n",
    "        y_last = self.y[-m:]\n",
    "\n",
    "        c3 = np.polyfit(t_last, y_last, deg=3)\n",
    "        t_future = np.arange(self.t[-1] + 1, self.t[-1] + days_ahead + 1)\n",
    "\n",
    "        y_poly = np.polyval(c3, t_future)\n",
    "\n",
    "        # ruido seg√∫n residuos del ajuste local\n",
    "        resid = y_last - np.polyval(c3, t_last)\n",
    "        sigma = np.std(resid)\n",
    "        np.random.seed(1997)\n",
    "        noise = np.random.normal(0.0, sigma, size=days_ahead)\n",
    "\n",
    "        y_future = y_poly + noise\n",
    "        return t_future, y_future\n",
    "\n",
    "\n",
    "analyzer = WeatherAnalyzer(dias, temps_clean[:, 1])\n",
    "\n",
    "smooth7 = analyzer.smooth(window=7)\n",
    "trend, seasonal, residual = analyzer.seasonal_decompose()\n",
    "future_days, future_vals = analyzer.forecast(days_ahead=30)\n",
    "\n",
    "print(\"smooth7 shape:\", smooth7.shape)\n",
    "print(\"trend shape:\", trend.shape)\n",
    "print(\"seasonal shape:\", seasonal.shape)\n",
    "print(\"residual shape:\", residual.shape)\n",
    "print(\"forecast shapes:\", future_days.shape, future_vals.shape)\n",
    "\n",
    "assert temps_clean.shape[1] == 2\n",
    "assert len(dias) == len(temps_clean)\n",
    "assert trend.shape == seasonal.shape == residual.shape == dias.shape\n",
    "assert future_days.shape == future_vals.shape == (30,)\n",
    "print(\"Todo OK ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a62a837-9d3b-4d0b-bc68-13170e7f9047",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ffe6f0; padding:18px; border-radius:12px; border:1px solid #f1aeb5\">\n",
    "\n",
    "### üå∏ Ejercicio2 ‚Äî Advanced Class with Inheritance/Decorators\n",
    "\n",
    "Cargue la serie de temperatura e implemente una estructura basada en clases:\n",
    "\n",
    "- `TimeSeriesAnalyzer` con suavizado (*moving average*).\n",
    "- Decorador `@vectorize` para operar por columnas.\n",
    "- `WeatherAnalyzer` con:\n",
    "  - ‚ú® `seasonal_decompose()` (trend, seasonal y residual).\n",
    "  - üîÆ `forecast()` usando ajuste polinomial y ruido.\n",
    "\n",
    "Se verific√≥ que todas las salidas tuvieran dimensiones correctas (`dias`, `temps_clean`, `trend`, `seasonal`, `residual`, `forecast`).\n",
    "\n",
    "**Conclusi√≥n**\n",
    "\n",
    "El modelo funciona correctamente y cumple con los objetivos del ejercicio.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b42fe0-5b31-46f7-b799-d69fb3e46aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed_weather.npz\n",
      "Guardado: subset.csv\n",
      "NPZ v√°lido: True | keys: ['temps_clean', 'anomalies', 'days']\n",
      "CSV v√°lido: True | shape: (100, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ejercicio 3: Robust I/O + Processed\n",
    "\n",
    "if \"dias\" not in globals() or \"temps_clean\" not in globals():\n",
    "    # fallback m√≠nimo: cargar desde archivo local\n",
    "    df = pd.read_csv(\"kumpula-weather-2017.csv\")\n",
    "    month = pd.to_numeric(df[\"m\"], errors=\"coerce\").to_numpy()\n",
    "    day   = pd.to_numeric(df[\"d\"], errors=\"coerce\").to_numpy()\n",
    "    temp  = pd.to_numeric(df[\"Air temperature (degC)\"], errors=\"coerce\").to_numpy()\n",
    "\n",
    "    month_days = np.array([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "    month_starts = np.concatenate(([0], np.cumsum(month_days)[:-1]))\n",
    "    dias = month_starts[month.astype(int)-1] + (day.astype(int)-1)\n",
    "\n",
    "    valid = np.isfinite(dias) & np.isfinite(temp)\n",
    "    dias = dias[valid].astype(float)\n",
    "    temp = temp[valid].astype(float)\n",
    "\n",
    "    ma30 = np.convolve(temp, np.ones(30)/30, mode=\"same\")\n",
    "    anomalies = temp - ma30\n",
    "    temps_clean = np.column_stack([temp, anomalies])\n",
    "\n",
    "# Variables principales\n",
    "days = np.asarray(dias, dtype=float)\n",
    "temp = np.asarray(temps_clean[:, 0], dtype=float)\n",
    "anomaly = np.asarray(temps_clean[:, 1], dtype=float)\n",
    "\n",
    "# smooth para subset\n",
    "temp_smooth = np.convolve(temp, np.ones(7)/7, mode=\"same\")\n",
    "\n",
    "\n",
    "np.savez(\"processed_weather.npz\", temps_clean=temps_clean, anomalies=anomaly, days=days)\n",
    "print(\"Guardado: processed_weather.npz\")\n",
    "\n",
    "\n",
    "n = min(100, len(days))\n",
    "subset = np.column_stack([days[:n], temp_smooth[:n], anomaly[:n]])\n",
    "\n",
    "np.savetxt(\n",
    "    \"subset.csv\",\n",
    "    subset,\n",
    "    delimiter=\",\",\n",
    "    fmt=\"%.2f\",\n",
    "    header=\"days,temp_smooth,anomaly\",\n",
    "    comments=\"\"\n",
    ")\n",
    "print(\"Guardado: subset.csv\")\n",
    "\n",
    "def load_and_validate(filename):\n",
    "    out = {\"filename\": filename, \"ok\": False, \"format\": None, \"arrays\": {}}\n",
    "\n",
    "    if filename.endswith(\".npz\"):\n",
    "        out[\"format\"] = \"npz\"\n",
    "        data = np.load(filename)\n",
    "\n",
    "        for k in data.files:\n",
    "            arr = np.asarray(data[k])\n",
    "            out[\"arrays\"][k] = arr\n",
    "\n",
    "        # Validaciones m√≠nimas\n",
    "        if \"temps_clean\" not in out[\"arrays\"]:\n",
    "            raise ValueError(\"NPZ inv√°lido: falta 'temps_clean'.\")\n",
    "\n",
    "        tc = out[\"arrays\"][\"temps_clean\"]\n",
    "        if tc.ndim != 2 or tc.shape[1] != 2:\n",
    "            raise ValueError(f\"'temps_clean' inv√°lido: shape esperado (N,2), recibido {tc.shape}.\")\n",
    "\n",
    "        for k, arr in out[\"arrays\"].items():\n",
    "            if np.issubdtype(arr.dtype, np.number):\n",
    "                if np.isnan(arr).any() or np.isinf(arr).any():\n",
    "                    raise ValueError(f\"'{k}' contiene NaN o Inf.\")\n",
    "\n",
    "        out[\"ok\"] = True\n",
    "        return out\n",
    "\n",
    "    elif filename.endswith(\".csv\"):\n",
    "        out[\"format\"] = \"csv\"\n",
    "        arr = np.loadtxt(filename, delimiter=\",\", skiprows=1)\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(1, -1)\n",
    "\n",
    "        # subset.csv debe ser (N,3)\n",
    "        if arr.shape[1] != 3:\n",
    "            raise ValueError(f\"CSV inv√°lido: se esperaban 3 columnas, recibidas {arr.shape[1]}.\")\n",
    "\n",
    "        if np.isnan(arr).any() or np.isinf(arr).any():\n",
    "            raise ValueError(\"CSV contiene NaN o Inf.\")\n",
    "\n",
    "        out[\"arrays\"][\"table\"] = arr\n",
    "        out[\"ok\"] = True\n",
    "        return out\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Formato no soportado. Usa .npz o .csv\")\n",
    "\n",
    "info_npz = load_and_validate(\"processed_weather.npz\")\n",
    "info_csv = load_and_validate(\"subset.csv\")\n",
    "\n",
    "print(\"NPZ v√°lido:\", info_npz[\"ok\"], \"| keys:\", list(info_npz[\"arrays\"].keys()))\n",
    "print(\"CSV v√°lido:\", info_csv[\"ok\"], \"| shape:\", info_csv[\"arrays\"][\"table\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50313b5b-cd3a-4f0a-86ce-05095c21ca9b",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ffe6f0; padding:18px; border-radius:12px; border:1px solid #f1aeb5\">\n",
    "\n",
    "### üå∏ Ejercicio 3 ‚Äî Robust I/O + Processed\n",
    "\n",
    "Se guardaron los datos procesados en:\n",
    "\n",
    "- `processed_weather.npz`, incluyendo las variables `temps_clean`, `anomalies` y `days`.\n",
    "- `subset.csv`, con los primeros 100 d√≠as y las columnas `days`, `temp_smooth` y `anomaly`, utilizando formato `%.2f`.\n",
    "\n",
    "Implementamos la funci√≥n `load_and_validate(filename)` para:\n",
    "\n",
    "- Cargar archivos en formato `.npz` o `.csv`.\n",
    "- Verificar la forma de los datos.\n",
    "- Comprobar la ausencia de valores `NaN` e `Inf`.\n",
    "\n",
    "La validaci√≥n fue correcta en ambos archivos (`True`), y el archivo `subset.csv` present√≥ dimensiones consistentes de `(100, 3)`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ece8af-a228-4a9e-a3ee-8ed589adb547",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ffe6f0; padding:18px; border-radius:12px; border:1px solid #ffb3d1; font-family: 'Segoe UI', sans-serif;\">\n",
    "\n",
    "<h3 style=\"color:black;\">üíó Preguntas 1. Fracci√≥n de outliers (IQR) y tipo de m√©todo:</h3>\n",
    "<p style=\"color:#444;\">\n",
    "La fracci√≥n removida es  \n",
    "\\( 1 - \\frac{N_{\\text{filtrados}}}{N_{\\text{total}}} \\).  \n",
    "El m√©todo IQR es robusto (no asume normalidad), generalmente conservador.  \n",
    "Alternativa: usar \\( \\mu \\pm 3\\sigma \\) (m√©todo 3-sigma).\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:black;\">üíó 2. Ejecuci√≥n de @vectorize (llamadas y forma):</h3>\n",
    "<p style=\"color:#444;\">\n",
    "Para <code>data.shape = (365,2)</code>, <code>smooth</code> se llama 2 veces (una por columna).  \n",
    "<code>results.T</code> se usa para recuperar la forma original (365,2).      \n",
    "Alternativa: <code>np.apply_along_axis</code>.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:black;\">üíó 3. Uso de FFT en seasonal_decompose:</h3>\n",
    "<p style=\"color:#444;\">\n",
    "Se resta la tendencia para aislar componentes peri√≥dicas.  \n",
    "Las top-4 frecuencias representan los ciclos dominantes (ej. semanal, mensual, anual).\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h3 style=\"color:black;\">üíó 4. Comparaci√≥n stats (raw vs smooth):</h3>\n",
    "<p style=\"color:#444;\">\n",
    "La desviaci√≥n est√°ndar disminuye al suavizar porque se reduce el ruido.  \n",
    "<code>polyfit</code> grado 2 captura bien la tendencia por su curvatura suave sin sobreajuste.\n",
    "</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3008ddb3-620b-4a79-b191-4b48fb81a921",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (marita)",
   "language": "python",
   "name": "marita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
